{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data     #data: Features (150 samples, 4 features each: sepal length, sepal width, petal length, petal width).\n",
    "y = data.target   #target: Labels (3 classes: Setosa, Versicolour, Virginica).\n",
    "\n",
    "# Binarize the output (Setosa vs. Not Setosa)\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)[:, 0]  # Setosa if 1, Not Setosa if 0\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Perceptron model\n",
    "perceptron = Perceptron(max_iter=100, eta0=0.1, random_state=42) \n",
    "# eta0:The learning rate, controlling the step size in the weight updates.\n",
    "\n",
    "# Train the Perceptron\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "predictions = perceptron.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Model accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4660 - accuracy: 0.8322\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3600 - accuracy: 0.8675\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3217 - accuracy: 0.8792\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2988 - accuracy: 0.8879\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2829 - accuracy: 0.8937\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2675 - accuracy: 0.8978\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2543 - accuracy: 0.9035\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2439 - accuracy: 0.9083\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2322 - accuracy: 0.9125\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2241 - accuracy: 0.9143\n",
      "313/313 - 1s - loss: 0.3269 - accuracy: 0.8884 - 581ms/epoch - 2ms/step\n",
      "\n",
      "Test accuracy: 0.8884000182151794\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Load the Fashion MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values of the images to be between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),  # Transforms the format of the images from a 2D array to a 1D array\n",
    "    Dense(300, activation='relu'), # First Dense layer with 128 nodes (neurons)\n",
    "    Dense(128, activation='relu'),  # second Dense layer with 128 nodes (neurons)\n",
    "    Dense(10, activation='softmax')  # third Dense layer with 10 nodes for 10 class labels\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "# Optimizer: 'Adam' is a popular optimizer that adjusts weights to minimize the loss function.\n",
    "#'sparse_categorical_crossentropy' is used as the loss function for multi-class classification problems where labels are provided as integers.\n",
    "# Metrics: 'accuracy' is used to evaluate the performance during training and testing.\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7397 - accuracy: 0.7590\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4943 - accuracy: 0.8296\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4481 - accuracy: 0.8448\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4216 - accuracy: 0.8529\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4016 - accuracy: 0.8596\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3870 - accuracy: 0.8636\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3742 - accuracy: 0.8676\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3622 - accuracy: 0.8713\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3528 - accuracy: 0.8736\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3439 - accuracy: 0.8765\n",
      "313/313 - 0s - loss: 0.4092 - accuracy: 0.8541 - 476ms/epoch - 2ms/step\n",
      "\n",
      "Test accuracy: 0.8540999889373779\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Load the Fashion MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values of the images to be between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),  # Transforms the format of the images from a 2D array to a 1D array\n",
    "    Dense(128, activation='relu'), # First Dense layer with 128 nodes (neurons)\n",
    "    Dense(128, activation='relu'),  # second Dense layer with 128 nodes (neurons)\n",
    "    Dense(10, activation='softmax')  # third Dense layer with 10 nodes for 10 class labels\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "# Optimizer: 'sgd' is generally simpler and uses a constant learning rate(0.01).\n",
    "#'sparse_categorical_crossentropy' is used as the loss function for multi-class classification problems where labels are provided as integers.\n",
    "# Metrics: 'accuracy' is used to evaluate the performance during training and testing.\n",
    "\n",
    "optimizer = SGD(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 34s 20ms/step - loss: 0.4792 - accuracy: 0.8260 - val_loss: 0.3418 - val_accuracy: 0.8765\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 33s 19ms/step - loss: 0.3090 - accuracy: 0.8861 - val_loss: 0.2936 - val_accuracy: 0.8892\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 33s 20ms/step - loss: 0.2647 - accuracy: 0.9020 - val_loss: 0.2690 - val_accuracy: 0.9018\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 32s 19ms/step - loss: 0.2317 - accuracy: 0.9137 - val_loss: 0.2584 - val_accuracy: 0.9040\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 32s 19ms/step - loss: 0.2045 - accuracy: 0.9224 - val_loss: 0.2531 - val_accuracy: 0.9087\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 34s 20ms/step - loss: 0.1802 - accuracy: 0.9320 - val_loss: 0.2485 - val_accuracy: 0.9150\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 36s 21ms/step - loss: 0.1612 - accuracy: 0.9395 - val_loss: 0.2439 - val_accuracy: 0.9152\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 33s 19ms/step - loss: 0.1447 - accuracy: 0.9454 - val_loss: 0.2519 - val_accuracy: 0.9110\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 32s 19ms/step - loss: 0.1271 - accuracy: 0.9514 - val_loss: 0.2587 - val_accuracy: 0.9148\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 32s 19ms/step - loss: 0.1132 - accuracy: 0.9567 - val_loss: 0.2549 - val_accuracy: 0.9165\n",
      "313/313 - 2s - loss: 0.2887 - accuracy: 0.9106 - 2s/epoch - 5ms/step\n",
      "Test accuracy: 0.9106000065803528\n"
     ]
    }
   ],
   "source": [
    "# simple CNN model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load the Fashion-MNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Build the convolutional  neural network model\n",
    "model = models.Sequential([\n",
    "    # Convolutional layers\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    \n",
    "    # Dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with the training data\n",
    "model.fit(train_images, train_labels, epochs=10, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model with the test data\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=2)\n",
    "\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "import numpy as np  # Add this line to import NumPy with the alias np\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
